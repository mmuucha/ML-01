{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWmv56NoWWwzhgt9t+c5o8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmuucha/ML-01/blob/main/Loan_Prediction_classification_Neural_NetworkV2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xfEdhyhEYaFK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd8WOk_bYgQf",
        "outputId": "b10ac5eb-0729-4fff-852c-4dfd9c08f7f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('revised_loan_default_dataset.csv')\n"
      ],
      "metadata": {
        "id": "RAR-HSD-giSV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns = data.columns.str.strip()\n"
      ],
      "metadata": {
        "id": "lyL5yGFXiN-R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate numerical and categorical columns\n",
        "numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns.tolist()"
      ],
      "metadata": {
        "id": "_U-II9EAgpCQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle null values\n",
        "data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())  # For numerical columns\n",
        "data[categorical_columns] = data[categorical_columns].fillna('Unknown')  # For categorical columns"
      ],
      "metadata": {
        "id": "RAX1E3i1hCI5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your features and target\n",
        "try:\n",
        "    X = data.drop('LoanDefault', axis=1)  # Assuming 'LoanDefault' is your target column\n",
        "    y = data['LoanDefault']\n",
        "except KeyError as e:\n",
        "    print(f\"KeyError: {e}. Available columns: {data.columns.tolist()}\")"
      ],
      "metadata": {
        "id": "SDHY_AWwhS0q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns to string if they are not already\n",
        "X[categorical_columns] = X[categorical_columns].astype(str)"
      ],
      "metadata": {
        "id": "UvAPW8QShTkP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your numerical and categorical features\n",
        "numerical_features = numerical_columns\n",
        "categorical_features = categorical_columns"
      ],
      "metadata": {
        "id": "gaVkF9pmhVL4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop('LoanDefault', axis=1), data['LoanDefault'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "YNliBcxJhYJp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'LoanDefault' is not in your feature lists\n",
        "numerical_features = [col for col in numerical_columns if col != 'LoanDefault']\n",
        "categorical_features = [col for col in categorical_columns if col != 'LoanDefault']"
      ],
      "metadata": {
        "id": "DUb58cH4jch1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features) # Set handle_unknown to 'ignore'\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "p641h2OqjooY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit the preprocessor on the training data and transform it\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "_Tx930pgjLu6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model creation\n",
        "model_1 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_processed.shape[1],)),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "    # Fit the model\n",
        "model_1.fit(X_train_processed, y_train, epochs=3, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9xyesyXjL78",
        "outputId": "d11935ef-2e63-4725-a77d-069e55d1a6a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 43ms/step - accuracy: 0.8982 - loss: 0.3475 - val_accuracy: 0.8984 - val_loss: 0.3292\n",
            "Epoch 2/3\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 42ms/step - accuracy: 0.9421 - loss: 0.1553 - val_accuracy: 0.6810 - val_loss: 0.6628\n",
            "Epoch 3/3\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 43ms/step - accuracy: 0.9999 - loss: 3.1833e-04 - val_accuracy: 0.8790 - val_loss: 0.3946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787f638b20b0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(X_test_processed, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2YAN3Ezk7JL",
        "outputId": "e523a65d-066d-4e2d-e2a2-c11e0a74d5f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8882 - loss: 0.3892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.384555459022522, 0.8898000121116638]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "still crap"
      ],
      "metadata": {
        "id": "TfXphCi7nDUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the new data\n",
        "new_data = pd.DataFrame({\n",
        "    'Date': ['2023-01-01'],\n",
        "    'Income': [2000],\n",
        "    'LoanAmount': [200000],\n",
        "    'CreditScore': [580],\n",
        "    'Age': [30],\n",
        "    'LoanDuration': [30],\n",
        "    'EmploymentStatus': ['Unmployed'],\n",
        "    'MaritalStatus': ['Single'],\n",
        "    'EducationLevel': ['Highschool']\n",
        "})\n",
        "\n",
        "# Transform the new data\n",
        "X_new = preprocessor.transform(new_data)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_1.predict(X_new)\n",
        "\n",
        "# Interpret the predictions\n",
        "predicted_classes = (predictions > 0.5).astype(int)  # Binarizing predictions\n",
        "print(\"Predicted classes:\", predicted_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mmZM_CMm68K",
        "outputId": "11bb9fc0-c146-4c83-b3b0-b88987c6d43a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "Predicted classes: [[0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DTZQ0pTm9ZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}